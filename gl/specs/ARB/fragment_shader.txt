Name

    ARB_fragment_shader

Name Strings

    GL_ARB_fragment_shader

Contributors

    Dave Baldwin
    Pat Brown
    Evan Hart
    Phil Huxley
    Dale Kirkland
    John Kessenich
    Steve Koren
    Jon Leech
    Bill Licea-Kane
    Benjamin Lipchak
    Barthold Lichtenbelt
    Kent Lin
    Jeremy Morris
    Teri Morrison
    Glenn Ortner
    Randi Rost
    Jeremy Sandmel

    The ARB_fragment_program working group members. Several concepts and
    chunks of text are copied from the ARB_fragment_program specification.

Contact

    Barthold Lichtenbelt, 3Dlabs, Inc. (barthold 'at' 3dlabs.com)
    Randi Rost, 3Dlabs, Inc. (rost 'at' 3dlabs.com)

Notice

    Copyright (c) 2003-2013 The Khronos Group Inc. Copyright terms at
        http://www.khronos.org/registry/speccopyright.html

IP Status

    As described in the Contributor License, which can be found at
    http://www.3dlabs.com/support/developer/ogl2/specs/3dlabs_contributor.pdf.

Status

    Complete. Approved by the ARB on June 11, 2003.
    Updated revision 0.79 approved by the ARB on June 17, 2004.

Version

    Last Modified Date: December 12, 2006
    Author Revision: 0.80

Number

    ARB Extension #32

Dependencies

    OpenGL 1.0 is required.

    This extension is written against version 1.10 of the OpenGL Shading
    Language Specification.

    The extension is written against the OpenGL 1.4 Specification.

    The ARB_shader_objects extension is required.

    This extension interacts with the ARB_vertex_shader extension.

Overview

    This extension adds functionality to define fragment shader objects. A
    fragment shader object is a shader object (see the ARB_shader_objects
    extension) that, when attached to a program object, can be compiled and
    linked to produce an executable that runs on the fragment processor in
    OpenGL. The fragment processor is a programmable unit that replaces the
    OpenGL 1.4 fixed-function texturing, color sum and fog stages. This
    extension also defines how such an executable interacts with the fixed
    functionality fragment processing of OpenGL 1.4. The language used to
    write fragment shaders is not discussed here. That language is defined
    in the OpenGL Shading Language specification as the Fragment Shading
    Language.

Issues
    1) Can you clarify texture unit, texture image unit and texture
       coordinate sets please?

    DISCUSSION: In 'old style' GL a texture unit consists of a texture
    coordinate processing unit (consisting of a texture matrix stack and
    texture coordinate generation state), and a texture image unit, with all
    the texture state defined in section 3.8, as well as texture environment
    state, as defined in section 3.8.12. The implementation dependent number
    of supported texture units in 'old style' GL is MAX_TEXTURE_UNITS.

    In this specification a texture unit consist of one or both of a texture
    image unit, and a texture coordinate set. The implementation dependent
    number of supported texture image units is MAX_TEXTURE_IMAGE_UNITS_ARB
    and the number of supported texture coordinate sets is
    MAX_TEXTURE_COORDS_ARB.

    The maximum available multi-texture stages (to the fixed-function
    pipeline) are MAX_TEXTURE_UNITS. A fragment shader has access to at
    least MAX_TEXTURE_UNITS texture image units, and possibly more, up to
    MAX_TEXTURE_IMAGE_UNITS_ARB. Where MAX_TEXTURE_IMAGE_UNITS_ARB is equal
    or greater than MAX_TEXTURE_UNITS.

    RESOLUTION: Yes

    2) Should we split the number of available texture coordinate sets and
       texture units?

    DISCUSSION: Some implementations might provide for more texture image
    units than texture coordinate sets. Texture coordinates for the 'new'
    texture image units can be derived from other texture coordinates, or
    provided through a texture lookup. These new texture coordinates can be
    used to index different textures bound to different texture image units.

    RESOLUTION: YES, splitting this is useful.

    3) Is the texture environment state associated with all texture image
       units?

    DISCUSSION: A fragment shader has access to the texture environment
    color through the shader built-in array gl_TexEnvColor. This array has
    MAX_TEXTURE_IMAGE_UNITS_ARB elements. It is also possible, and useful,
    to set the texture environment state TEXTURE_LOD_BIAS for all texture
    image units. All other texture environment state is not accessible to a
    fragment shader (for example, TEXTURE_ENV_MODE, COMBINE_RGB etc).
    However, an application can still set this state (and query it).

    Note that fixed-function GL caps the number of supported texture stages
    to MAX_TEXTURE_UNITS. This limit is generally below the number of
    texture image units available to a fragment shader. Each of these
    MAX_TEXTURE_UNITS texture stages need all texture environment state for
    the multi-texture pipeline to function correctly. Texture units above
    this limit still have all the texture environment state associated with
    it, even although this state is not accessible in a fragment shader.

    Note that ARB_fragment_program also does this, except that it caps
    access to the texture environment state to the first MAX_TEXTURE_UNITS
    texture image units.

    RESOLUTION: Yes.

    4) What to do about invariance rules (Appendix A)?

    DISCUSSION: Numerous rules and proposals have been discussed. In the
    end, simplicity is an important goal. It is always possible to later add
    more invariance rules, if it turns out to be desirable.

    RESOLUTION: The same shader will produce the same result when run
    multiple times with the same input. The wording 'the same shader' means
    a program object that is populated with the same source strings, which
    are compiled and then linked, possibly multiple times. This program
    object is executed using the same GL state vector.

    Besides the above general statement, we will limit this specification to
    one invariance rule with respect to depth produced by a fragment shader:

    All shaders that either conditionally or unconditionally copy the input
    gl_FragCoord.z to the output gl_FragDepth are depth-invariant with
    respect to each other, for those fragments where this copy actually is
    done.

    Note that a fragment shader that does not write to gl_FragDepth is
    depth-invariant with fixed function (since fixed function depth will be
    used for the fragment when gl_FragDepth is not written).

    See also Appendix A.

    5) Should the output from the pixel rectangle rasterization and bitmap
       rasterization stages feed into a fragment shader?

    DISCUSSION: See also Issue 2 in the OpenGL Shading Language
    specification. Future API additions could make the operations DrawPixels
    performs programmable. For the list of specific operations that could be
    replaced see Section 3.6.4, Figure 3.7 in the OpenGL 1.4 specification.
    Combined with the proposed pack/unpack language, and the proposed pack
    and unpack processors, such a future extension will become an extremely
    powerful and flexible imaging pipeline.

    Most of the harder parts to implement the functionality in Figure 3.7
    result from the imaging subset. A conceivable way to implement this
    functionality is by using the programmable fragment unit. However, if
    the results from the pixel rectangle and bitmap rasterization stages did
    feed into the fragment shader, then implementing all the functionality
    in Figure 3.7 might become hard or impossible, when a fragment shader is
    also active. A possibility that was considered was to say that if a
    fragment shader was active, pixel transfer functionality such as scale
    and bias, color matrix, lookup, etc., was disabled. A fragment shader
    could perform these kinds of operations, after all.

    ARB_fragment_program does feed the result of pixel rectangle and bitmap
    rasterization into the fragment shader.

    RESOLUTION: Yes, this allows fragment shaders to do image processing
    type of operations on pixel rectangles and bitmaps.

    Note that a fragment shader that is processing fragments resulting from
    rasterization of pixel rectangles or bitmaps, can only reference
    built-in varying variables starting with "gl_" (gl_Color,
    gl_SecondaryColor, gl_TexCoord[] and gl_FogFragCoord). The fragments
    produced as a result of rasterizing a pixel rectangle or bitmap have
    associated values for those varying variables. If the fragment shader
    uses a user-defined varying, results are undefined.

    6) What about clamping and conversion for color and depth output
       variables?

    DISCUSSION: The output variables gl_FragDepth and gl_FragColor are in
    floating point format. However, the GL 1.4 pipeline following the
    fragment shader expects these values to be in fixed-point, and clamped
    to the range [0,1].

    RESOLUTION: Color and depth values written by the fragment shader will
    be automatically clamped to the range [0,1] and then converted, as
    appropriate, to a fixed-point representation. See section 3.11.6.

    7) What about clamping and conversion for color and depth input varying
       variables?

    DISCUSSION: This ties in with issue 18 in the ARB_vertex_shader
    specification. There are three cases to consider:

      1) An ARB_vertex_shader shader writing colors that are consumed by an
         ARB_fragment_shader shader.
      2) An ARB_vertex_program shader writing colors that are consumed by an
         ARB_fragment_shader shader.
      3) Fixed functionality vertex processing outputting colors that are
         consumed by an ARB_fragment_shader shader.

    Fixed function vertex processing as well as ARB_vertex_shader and
    ARB_vertex_program do clamp colors automatically to [0,1]. In all three
    cases colors are next converted to fixed-point (section 2.13.9).

    RESOLUTION: Depth and color values will be converted to floating-point
    before entering the fragment shader.

    8) What controls the value of the shader built-in Boolean
       gl_FrontFacing?

    DISCUSSION: The OpenGL Shading Language says the following: "The
    fragment shader has access to the read-only built-in variable
    gl_FrontFacing whose value is true if the fragment belongs to a
    front-facing primitive."

    This specification defines when a fragment is considered front-facing.

    A fragment derives its facing direction from the primitive that
    generates the fragment. All fragments generated by primitives other than
    polygons, triangles, or quadrilaterals are considered to be front
    facing. For all other fragments (including ones resulting from point-
    and line-mode polygons) the determination is made by examining the sign
    of the area computed by equation 2.6 of section 2.13.1 (including the
    possible reversal of this sign as indicated by the last call to
    FrontFace). If the sign is positive then the fragments are front facing;
    otherwise, they are back facing.

    ARB_vertex_shader has an enable called VERTEX_PROGRAM_TWO_SIDE_ARB. If
    false, the front color is always selected. However, this enable does not
    apply to the front or back facing determination of a fragment. The value
    of VERTEX_PROGRAM_TWO_SIDE_ARB does not affect the value of
    gl_FrontFacing. Thus you can have the following situation:

      * VERTEX_PROGRAM_TWO_SIDE_ARB = FALSE. Which forces the front color to
        always be selected. Thus gl_Color and gl_SecondaryColor (read-only
        accessible in the fragment shader) have the values of the varyings
        gl_FrontColor and gl_FrontSecondaryColor (written by the vertex
        shader).
      * The primitive is a polygon and is determined to be back-facing.
        gl_FrontFacing therefore = FALSE.

    RESOLUTION: Depending on the primitive type it is either always front
    facing, or it is determined by he sign of the polygon's area computed in
    window coordinates.

    9) OpenGL provides a hierarchy of texture enables (cube map, 3D, 2D,
       1D). Should samplers override that hierarchy and select specific
       texture targets?

    DISCUSSION: How samplers work is explained in issue 25 of the
    ARB_shader_objects specification.

    RESOLUTION: Yes. This removes a potential pitfall for developers:
    Leaving the hierarchy of enables in an undesired state. It makes shaders
    more readable as the intent of the code is more obvious. It allows
    compilers to be more aggressive as to which texture coordinate
    components are "don't cares" without having to recompile programs when
    fixed-function texture enables change.

    Note that the ARB_shader_objects specification states that it is not
    allowed to have samplers of different types point to the same texture
    image unit. For example, it is not possible to request a 2D and a 3D
    texture lookup using the same texture image unit within a program
    object.

    10) Is Depth Offset applied to the window z value before it enters the
        fragment shader?

    DISCUSSION: Depth Offset (polygon offset) is discussed in section 3.5.5
    of the GL 1.4 spec. Depth offset is considered part of the rasterization
    stage, which happens prior to processing of a fragment shader.

    RESOLUTION: As in the base OpenGL specification, the depth offset
    generated by polygon offset is added during polygon rasterization. The
    depth value provided to shaders in the built-in gl_FragCoord.z already
    includes polygon offset, if enabled. If the depth value is replaced by a
    fragment shader, the polygon offset value will NOT be recomputed and
    added back after shader execution.

    NOTE: This is probably not desirable for fragment shaders that modify
    depth values since the partials used to generate the offset may not
    match the partials of the computed depth value.

    11) Should gl_FragColor be aliased to gl_FragData[0]?

    RESOLUTION: No. A shader should write either gl_FragColor, or
    gl_FragData[n], but not both.

    12) Should gl_FragData[n] be clamped?

    RESOLUTION: gl_FragData[] is basically an array of colors. The values in
    this array might or might not be actual color data, just as is true for
    the output variable gl_FragColor. The data assigned to gl_FragData[n]
    will be clamped to [0,1]. This restriction can be lifted by a separate
    extension, for example by the proposed color_clamp_control extension.

    13) What texture operations are not affected by a fragment shader
        performing a texture lookup?

    RESOLUTION: Whether or not a fragment shader is active, the following
    operations still behave as specified:

      * texture image specification (pp. 119-128)
      * alternate texture image specification (pp. 128-132)
      * compressed texture image specification (pp. 132-135)
      * texture parameters behave as specified even when a texture is
        accessed from within a fragment shader (pp. 135-147)
      * texture state and proxy state (pp. 148-149)
      * texture object specification (pp. 149-152)
      * texture comparison modes (p. 157)

    14) What is the interaction with a possible MRT (Multiple Render Target)
        extension?

    The OpenGL Shading Language defines the array gl_FragData[] to output
    values to multiple buffers. There are two situations to consider.

      1) There is no MRT extension support. A shader can statically assign a
         value to either gl_FragColor or gl_FragData[0] (but not both).
         Either way the same buffer will be targeted.
      2) There is MRT support. In this case what happens is defined in the
         relevant MRT extension documentation.

New Procedures and Functions

    None

New Tokens


        FRAGMENT_SHADER_ARB                             0x8B30


        MAX_FRAGMENT_UNIFORM_COMPONENTS_ARB             0x8B49
        MAX_TEXTURE_COORDS_ARB                          0x8871
        MAX_TEXTURE_IMAGE_UNITS_ARB                     0x8872


        FRAGMENT_SHADER_DERIVATIVE_HINT_ARB             0x8B8B

