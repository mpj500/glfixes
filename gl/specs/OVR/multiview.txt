Name

    OVR_multiview

Name Strings

    GL_OVR_multiview

Contact

    Cass Everitt, Oculus (cass.everitt 'at' oculus.com)

Contributors

    John Carmack, Oculus
    Tom Forsyth, Oculus
    Maurice Ribble, Qualcomm
    James Dolan, NVIDIA Corporation
    Mark Kilgard, NVIDIA Corporation
    Michael Songy, NVIDIA Corporation
    Yury Uralsky, NVIDIA Corporation
    Jesse Hall, Google
    Timothy Lottes, Epic
    Jan-Harald Fredriksen, ARM
    Jonas Gustavsson, Sony Mobile
    Sam Holmes, Qualcomm

Status

    Incomplete.

Version

    Last Modified Date:  Apr 15, 2015
    Author Revision: 0.4

Number

    OpenGL Extension #478
    OpenGL ES Extension #241

Dependencies

    OpenGL 3.0 or OpenGL ES 3.0 is required.

Overview

 
    The method of stereo rendering supported in OpenGL is currently achieved by
    rendering to the two eye buffers sequentially.  This typically incurs double
    the application and driver overhead, despite the fact that the command
    streams and render states are almost identical.

    This extension seeks to address the inefficiency of sequential multiview
    rendering by adding a means to render to multiple elements of a 2D texture
    array simultaneously.  In multiview rendering, draw calls are instanced into
    each corresponding element of the texture array.  The vertex program uses a
    new ViewID variable to compute per-view values, typically the vertex
    position and view-dependent variables like reflection.

    The formulation of this extension is high level in order to allow
    implementation freedom.  On existing hardware, applications and drivers can
    realize the benefits of a single scene traversal, even if all GPU work is
    fully duplicated per-view.  But future support could enable simultaneous
    rendering via multi-GPU, tile-based architectures could sort geometry into
    tiles for multiple views in a single pass, and the implementation could even
    choose to interleave at the fragment level for better texture cache
    utilization and more coherent fragment shader branching. 

    The most obvious use case in this model is to support two simultaneous
    views: one view for each eye.  However, we also anticipate a usage where two
    views are rendered per eye, where one has a wide field of view and the other
    has a narrow one.  The nature of wide field of view planar projection is
    that the sample density can become unacceptably low in the view direction.
    By rendering two inset eye views per eye, we can get the required sample
    density in the center of projection without wasting samples, memory, and
    time by oversampling in the periphery.


New Tokens


        FRAMEBUFFER_ATTACHMENT_TEXTURE_NUM_VIEWS_OVR               0x9630
        FRAMEBUFFER_ATTACHMENT_TEXTURE_BASE_VIEW_INDEX_OVR         0x9632


        MAX_VIEWS_OVR                                              0x9631


        FRAMEBUFFER_INCOMPLETE_VIEW_TARGETS_OVR                    0x9633


New Procedures and Functions

    void FramebufferTextureMultiviewOVR( enum target, enum attachment, uint texture, int level, int baseViewIndex, sizei numViews );

