Name

    NV_float_buffer

Name Strings

    GL_NV_float_buffer
    WGL_NV_float_buffer
    GLX_NV_float_buffer

Contact

    Pat Brown, NVIDIA Corporation (pbrown 'at' nvidia.com)

Notice

    Copyright NVIDIA Corporation.

IP Status

    NVIDIA Proprietary.

Status

    Implemented in CineFX (NV30) Emulation driver, August 2002.
    Shipping in Release 40 NVIDIA driver for CineFX hardware, January 2003.

    Superseded by the more general ARB_texture_float and
    ARB_color_buffer_float extensions.  However, NV3x-based GPUs are not
    capable enough to support the generality of the ARB extensions so
    the NV_float_buffer extension remains available for NV3x development
    and backward compatibility.

Version

    Last Modified:      2006/11/03
    NVIDIA Revision:    20

Number

    281

Dependencies

    Written based on the wording of the OpenGL 1.3 specification and the
    WGL_ARB_pixel_format extension specification.

    The following extensions are required:
        * NV_fragment_program
        * NV_texture_rectangle
        * WGL_ARB_pixel_format
        * WGL_ARB_render_texture
        * WGL_NV_render_texture_rectangle

    EXT_paletted_texture trivially affects the definition of this extension.

    SGIX_depth_texture trivially affects the definition of this extension.

    NV_texture_shader trivially affects the definition of this extension.

    NV_half_float trivially affects the definition of this extension.

    ARB_color_buffer_float and ATI_pixel_format_float affect the definition of
    this extension.

    ARB_texture_float and ATI_texture_float affect the definition of this
    extension.

    This extension modifies EXT_framebuffer_object.

Overview

    This extension builds upon NV_fragment_program to provide a framebuffer
    and texture format that allows fragment programs to read and write
    unconstrained floating point data.

    In unextended OpenGL, most computations dealing with color or depth
    buffers are typically constrained to operate on values in the range [0,1].
    Computational results are also typically clamped to the range [0,1].
    Color, texture, and depth buffers themselves also hold values mapped to
    the range [0,1].

    The NV_fragment_program extension provides a general computational model
    that supports floating-point numbers constrained only by the precision of
    the underlying data types.  The quantites computed by fragment programs do
    not necessarily correspond in number or in range to conventional
    attributes such as RGBA colors or depth values.  Because of the range and
    precision constraints imposed by conventional fixed-point color buffers,
    it may be difficult (if not impossible) to use them to implement certain
    multi-pass algorithms.

    To enhance the extended range and precision available through fragment
    programs, this extension provides floating-point RGBA color buffers that
    can be used instead of conventional fixed-point RGBA color buffers.  A
    floating-point RGBA color buffer consists of one to four floating-point
    components stored in the 16- or 32-bit floating-point formats (fp16 or
    fp32) defined in the NV_half_float and NV_fragment_program extensions.

    When a floating-point color buffer is used, the results of fragment
    programs, as written to the "x", "y", "z", and "w" components of the
    o[COLR] or o[COLH] output registers, are written directly to the color
    buffer without any clamping or modification.  Certain per-fragment
    operations are bypassed when rendering to floating-point color buffers.

    A floating-point color buffer can also be used as a texture map, either by
    reading back the contents and then using conventional TexImage calls, or
    by using the buffer directly via the ARB_render_texture extension or
    the EXT_framebuffer_object extension.

    This extension has many uses.  Some possible uses include:

        (1) Multi-pass algorithms with arbitrary intermediate results that
            don't have to be artifically forced into the range [0,1].  In
            addition, intermediate results can be written without having to
            worry about out-of-range values.

        (2) Deferred shading algorithms where an expensive fragment program is
            executed only after depth testing is fully complete.  Instead, a
            simple program is executed, which stores the parameters necessary
            to produce a final result.  After the entire scene is rendered, a
            second pass is executed over the entire frame buffer to execute
            the complex fragment program using the results written to the
            floating-point color buffer in the first pass.  This will save the
            cost of applying complex fragment programs to fragments that will
            not appear in the final image.

        (3) Use floating-point texture maps to evaluate functions with
            arbitrary ranges.  Arbitrary functions with a finite domain can be
            approximated using a texture map holding sample results and
            piecewise linear approximation.

    There are several significant limitations on the use of floating-point
    color buffers.  First, floating-point color buffers do not support frame
    buffer blending.  Second, floating-point texture maps do not support
    mipmapping or any texture filtering other than NEAREST.  Third,
    floating-point texture maps must be 2D, and must use the
    NV_texture_rectangle extension.

Issues

    Should the extension create a separate non-RGBA pixel formats or simply
    extend existing RGBA formats?

        RESOLVED:  Extend existing RGBA formats.  Since fragment programs
        generally build on RGBA semantics, it's cleaner to avoid creating a
        separate "XYZW" mode.  There are several special semantics that need
        to be added:  clear color state is now not clamped, and ReadPixels
        will clamp to [0,1] only if the source data comes from fixed-point
        color buffers.

        Fragment programs can be written that store data completely unrelated
        to color into a floating-point "RGBA" buffer.
 
    Can floating-point color buffers be displayed?  If so, how?

        RESOLVED:  Not in this extension.  Floating-point color buffers can be
        used only as pbuffers.  Hardware necessary to display floating-point
        color buffers would be expensive and consume significant memory
        bandwidth.

    Is it possible to encode more than four distinct values in a
    floating-point color buffer?

        RESOLVED:  Yes.  The NV_fragment_program extension contains pack and
        unpack instructions (PK2H, PK2US, PK4B, PK4UB, PK4UBG, UP2H, UP2US,
        UP4B, UP4UB, UP4UBG) that allow fragment programs to encode multiple
        values into a single 32-bit component.  In particular, it is possible
        to pack two half-precision floats, two normalized unsigned shorts, or
        four normalized signed or unsigned bytes into a single 32-bit
        component.

        A program can use a pack instruction to pack multiple values into a
        single 32-bit component and then write the resulting component to a
        floating-point color buffer with 32-bit components.  On a subsequent
        rendering pass, a program can read back the stored data (using texture
        mapping) and use the equivalent unpack instruction to restore the
        original values.  The only data lost in this process comes from the
        loss of precision or clamping in the packing operation, where the
        original values are converted to data types with lower precision or a
        smaller data range.

    What happens when rendering to an floating-point color buffer if fragment
    program mode is disabled?  Or when fragment program mode is enabled, but
    no program is loaded?

        RESOLVED:  Fragment programs are required to use floating-point color
        buffers.  An INVALID_OPERATION error is generated by any GL command
        that generates fragments if FRAGMENT_PROGRAM_NV is disabled.  The same
        behavior already exists for conventional frame buffers if
        FRAGMENT_PROGRAM_NV is enabled but the bound fragment program is
        invalid.

    Should alpha test be supported with floating-point color buffers?

        RESOLVED:  No.  It is trivial to implement an alpha test in a fragment
        program using the KIL instruction, which requires no dedicated frame
        buffer logic.

    Should blending be supported with floating-point color buffers?

        RESOLVED:  Not in this extension.  While blending would clearly be
        useful, full-precision floating-point blenders are expensive.  In
        addition, a computational model more general than traditional blending
        (with its 1-x operations and clamping) is desirable.  The traditional
        OpenGL blending model would not be the most suitable computational
        model for future blend-enabled floating-point color buffers.

        An alternative to conventional blending (operating at a coarser
        granularity) is to (1) render a pass into the color buffer, (2) bind
        the color buffer as a texture rectangle using this extension and
        ARB_render_texture, (3) perform texture lookups in a fragment program
        using the TEX instruction with f[WPOS].xy as a 2D texture coordinate,
        and (4) perform the necessary blending between the passes using the
        same fragment program.

    Should we provide accumulation buffers for pixel formats with
    floating-point color buffers?

        RESOLVED:  No.  Accumulation operations contents can be achieved using
        fragment programs to perform the accumulation, which requires no
        dedicated frame buffer logic.

    Should fragment program color results be converted to match the format of
    the frame buffer, or should an error result?  For example, what if we
    write to o[COLR] but have a 16-bit frame buffer?

        RESOLVED:  Conversions can be performed simply in hardware, so no
        error semantics are required.  This mechanism also allows the same
        programs to be shared between contexts with different pixel formats.

        Applications should be aware that if color components contain packed
        data, a data type mismatch may result in a floating-point data
        conversion that corrupts the packed data.

    How should floating-point color buffers interact with multisampling?  For
    normal color buffers, the multiple samples for each pixel are required to
    be filtered down to a single pixel in the color buffer.  Similar filtering
    on floating-point color buffers does not necessarily make sense.  Should
    there even be a normal color buffer in this case?
    
        RESOLVED:  The initial implementation of this extension does not
        provide floating-point color buffers that support multisampling.

        Multisample fragment operations (e.g., SAMPLE_COVERAGE) are explicitly
        not supported by extension.  This extension does not modify the
        portion of the spec where multiple samples are resolved to a single
        color value.  So if floating-point color buffers were provided, the
        multiple samples are filtered down to a single result value, most
        likely by computing a per-component average value.

    Conventional RGBA primitive antialiasing multiplies coverage by the alpha
    component of the fragment's color, with the assumption that alpha blending
    will be performed.  How does antialiasing work with floating-point color
    buffers?

        RESOLVED:  It doesn't.  The computed coverage is not accessible to
        fragment programs and is discarded.  Note also that conventional
        antialiasing requires alpha blending, which does not work for
        floating-point color buffers.

    What are the semantics for ReadPixels when using an floating-point color
    buffer?

        RESOLVED:  ReadPixels from a floating-point color buffer works like
        any other RGBA read, except that the final results are not clamped to
        the range [0,1].  This ensures that we can save and restore
        floating-point color buffers using ReadPixels/DrawPixels.

    What are the semantics for Bitmap when using an floating-point color
    buffer?

        RESOLVED:  Bitmap generates fragments using the current raster
        attributes, which are then passed to fragment programs like any other
        fragments.  Bitmaps will be drawn using the color of the current
        raster position, whose components are clamped to [0,1] when the raster
        position is sent.

    What are the semantics for DrawPixels when using a floating-point color
    buffer?  How about CopyPixels?

        RESOLVED:  DrawPixels generates fragments with the originally
        specified color values; components are not clamped to [0,1].  For
        fixed-point color buffers, DrawPixels will generate fragments with
        clamped color components.  

        CopyPixels is defined in the spec as a ReadPixels followed by a
        DrawPixels, and will operate similarly.

        This mechanism allows applications to write floating-point data
        directly into a floating-point color buffer without any clamping.
        Since DrawPixels and CopyPixels generate fragments and fragment
        programs are required to render to floating-point color buffers, a
        fragment program is still required to load a floating-point color
        buffer using DrawPixels.

    What are the semantics for Clear when using an floating-point color
    buffer?

        RESOLVED:  Clears work as normal, except that values outside the range
        [0,1] can be written to the color buffer.  The core spec is modified
        so that clear color values are not clamped to [0,1].  Instead, for
        fixed-point color buffers, clear colors are clamped to [0,1] at clear
        time.

        For compatibility with conventional OpenGL, queries of
        CLEAR_COLOR_VALUE will clamp components to [0,1].  A separate
        FLOAT_CLEAR_COLOR_VALUE_NV query is added to query unclamped color
        clear values.

    Why don't floating-point textures support filtering?  What can be done to
    achieve texture filtering?
    
        RESOLVED:  Extended OpenGL texture filtering (including mipmapping and
        support for anisotropic filters) is very computationally expensive.
        Even simple linear filtering for floating-point textures with large
        components is expensive.

        Linear filters can be implemented in fragment programs by doing
        multiple lookups into the same texture.  Since fragment programs allow
        the use of arbitrary coordinates into arbitrary texture maps, this
        type of operation can be easily done.

        A 1D linear filter can be implemented using an nx1 texture rectangle
        with the following (untested) fragment program, assuming the 1D
        coordinate is in f[TEX0].x:

            ADDR H2.xy, f[TEX0].x, {0.0, 1.0};
            FRCH H3.x, R1.x;             # compute the blend factor
            TEX  H0, H2.x, TEX0, RECT;   # lookup 1st sample
            TEX  H1, H2.y, TEX0, RECT;   # lookup 2nd sample
            LRPH H0, H3.x, H1, H0;       # blend
            
        A 2D linear filter can be implemented similarly, assuming the 2D
        coordinate is in f[TEX0].xy:

            ADDH H2, f[TEX0].xyxy, {0.0, 0.0, 1.0, 1.0};
            FRCH H3.xy, H2.xyxy;         # base weights
            ADDH H3.zw, 1.0, -H3.xyxy;   # 1-base weights
            MULH H3, H3.xzxz, H3.yyww;   # bilinear filter weights
            TEX H1, R2.xyxy, TEX0, RECT; # lookup 1st sample
            MULH H0, H1, H3.x;           # blend
            TEX H1, R2.zyzy, TEX0, RECT; # lookup 2nd sample
            MADH H0, H1, H3.y, H0;       # blend
            TEX H0, R2.xwxw, TEX0, RECT; # lookup 3rd sample
            MADH H0, H1, H3.z, H0;       # blend
            TEX H1, R2.zwzw, TEX0, RECT; # lookup 4th sample
            MADH H0, H1, H3.w, H0;       # blend

        Fragment programs can be used to perform more-or-less arbitrary
        filtering using similar methods, and the DDX and DDY instructions can
        be used to refine the shape of the filter.

    Why must the NV_texture_rectangle extension be used in order to use
    floating-point texture maps?

        RESOLVED:  On many graphics hardware platforms, texture maps are
        stored using a special memory encodings designed to optimize rendering
        performance.  In current hardware, conventional texture maps usually
        top out at 32 bits per texel.  The logic required to encode and decode
        128-bit texels (and frame buffer pixels) optimally is substantially
        more complex.

    What happens if you try to use an floating-point texture without a
    fragment program?

        RESOLVED:  No error is generated, but that texture is effectively
        disabled.  This is similar to the behavior if an application tried to
        use a normal texture having an inconsistent set of mipmaps.

    How does NV_float_buffer interact with the OpenGL 1.2 imaging subset?

        RESOLVED:  The imaging subset as specified should work properly with
        floating-point color buffers, but is not modified by this extension.
        There are imaging operations (e.g., color tables, histograms) that
        expect the components they operate on to be in the range [0,1], and
        this extension makes no attempt to extend such functionality.

    How does NV_float_buffer interact with SGIS_generate_mipmap?

        RESOLVED:  Since this extension supports only texture rectangles
        (which have no mipmaps), this issue is moot.  

        In the general case, mipmaps should be generated using an appropriate
        downsample filter, where floating-point component values are averaged.
        Components should not be clamped during any such mipmap generation.

    What is the deal with the names of the clear color query tokens?

        RESOLVED:  The "normal" OpenGL clear color (clamped to [0,1]) is
        queried using the token COLOR_CLEAR_VALUE.  This extension provides a
        new query for unclamped values, using the token
        FLOAT_CLEAR_COLOR_VALUE_NV.  Notice that "CLEAR" and "COLOR" are
        reversed due to a mistake made when the spec was first written.  This
        spec lists the core query token, and originally had "CLEAR" and
        "COLOR" reversed there, too.  

        Then again, the core specification is inconsistent since the queried
        state is set by calling glClearColor(), with "Clear" before "Color".

    What performance issues exist with this functionality?

        See the "NV3x Implementation Issues" section of the
        specification.

    How should the texture border color (values) be handled for float
    textures?

        RESOLVED:  Clamp the texture border color (values) to [0,1]
        when sampling a float texture's border.  In core OpenGL 1.0, the
        texture border color components are clamped to the range [01,].
        The NV_texture_shader extension added support for signed texture
        components.  We decided to provide GL_TEXTURE_BORDER_VALUES as
        a way of specifying a version of the texture border color whose
        components were not clamped to [0,1] when set.  This was to
        provide a way of specifying negative texture border components.

        In practice, that has not proven particularly useful.  No real
        applications are known to have specified negative texture border
        values components.

        Ideally, the unclamped GL_TEXTURE_BORDER_VALUES state could
        provide an unclamped (unmassaged) set of floating-point color
        components for the texture border color.  This requires an
        additional 96 bits of state per texture unit to support this,
        and based on the experience with NV_texture_shader's support for
        texture border values outside the [0,1] range, it is simply not
        worth it.

        For compatibility with the NV_texture_shader extension, we
        provide language saying that floating-point textures clamp
        the components of the TEXTURE_BORDER_VALUES vector [0,1] when
        sampling the border color.


New Procedures and Functions

    None.

New Tokens


        FLOAT_R_NV                                      0x8880
        FLOAT_RG_NV                                     0x8881
        FLOAT_RGB_NV                                    0x8882
        FLOAT_RGBA_NV                                   0x8883
        FLOAT_R16_NV                                    0x8884
        FLOAT_R32_NV                                    0x8885
        FLOAT_RG16_NV                                   0x8886
        FLOAT_RG32_NV                                   0x8887
        FLOAT_RGB16_NV                                  0x8888
        FLOAT_RGB32_NV                                  0x8889
        FLOAT_RGBA16_NV                                 0x888A
        FLOAT_RGBA32_NV                                 0x888B


        TEXTURE_FLOAT_COMPONENTS_NV                     0x888C


        FLOAT_CLEAR_COLOR_VALUE_NV                      0x888D
        FLOAT_RGBA_MODE_NV                              0x888E


        WGL_FLOAT_COMPONENTS_NV                         0x20B0
        WGL_BIND_TO_TEXTURE_RECTANGLE_FLOAT_R_NV        0x20B1
        WGL_BIND_TO_TEXTURE_RECTANGLE_FLOAT_RG_NV       0x20B2
        WGL_BIND_TO_TEXTURE_RECTANGLE_FLOAT_RGB_NV      0x20B3
        WGL_BIND_TO_TEXTURE_RECTANGLE_FLOAT_RGBA_NV     0x20B4


        WGL_TEXTURE_FLOAT_R_NV                          0x20B5
        WGL_TEXTURE_FLOAT_RG_NV                         0x20B6
        WGL_TEXTURE_FLOAT_RGB_NV                        0x20B7
        WGL_TEXTURE_FLOAT_RGBA_NV                       0x20B8


        GLX_FLOAT_COMPONENTS_NV                         0x20B0

