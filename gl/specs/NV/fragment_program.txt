Name
    
    NV_fragment_program

Name Strings

    GL_NV_fragment_program

Contact

    Pat Brown, NVIDIA Corporation (pbrown 'at' nvidia.com)
    Mark J. Kilgard, NVIDIA Corporation (mjk 'at' nvidia.com)

Notice

    Copyright NVIDIA Corporation, 2001-2002.

IP Status

    NVIDIA Proprietary.

Status

    Implemented in CineFX (NV30) Emulation driver, August 2002.
    Shipping in Release 40 NVIDIA driver for CineFX hardware, January 2003.

Version

    Last Modified Date:  2005/05/24
    NVIDIA Revision:     73

Number

    282

Dependencies

    Written based on the wording of the OpenGL 1.2.1 specification and
    requires OpenGL 1.2.1.

    Requires support for the ARB_multitexture extension with at least
    two texture units.

    NV_vertex_program affects the definition of this extension.  The only
    dependency is that both extensions use the same mechanisms for defining
    and binding programs.

    NV_texture_shader trivially affects the definition of this extension.

    NV_texture_rectangle trivially affects the definition of this extension.

    ARB_texture_cube_map trivially affects the definition of this extension.

    EXT_fog_coord trivially affects the definition of this extension.

    NV_depth_clamp affects the definition of this extension.

    ARB_depth_texture and SGIX_depth_texture affect the definition of this
    extension.

    NV_float_buffer affects the definition of this extension.

    ARB_vertex_program affects the definition of this extension.

    ARB_fragment_program affects the definition of this extension.

Overview

    OpenGL mandates a certain set of configurable per-fragment computations
    defining texture lookup, texture environment, color sum, and fog
    operations.  Each of these areas provide a useful but limited set of fixed
    operations.  For example, unextended OpenGL 1.2.1 provides only four
    texture environment modes, color sum, and three fog modes.  Many OpenGL
    extensions have either improved existing functionality or introduced new
    configurable fragment operations.  While these extensions have enabled new
    and interesting rendering effects, the set of effects is limited by the
    set of special modes introduced by the extension.  This lack of
    flexibility is in contrast to the high-level of programmability of
    general-purpose CPUs and other (frequently software-based) shading
    languages.  The purpose of this extension is to expose to the OpenGL
    application writer an unprecedented degree of programmability in the
    computation of final fragment colors and depth values.

    This extension provides a mechanism for defining fragment program
    instruction sequences for application-defined fragment programs.  When in
    fragment program mode, a program is executed each time a fragment is
    produced by rasterization.  The inputs for the program are the attributes
    (position, colors, texture coordinates) associated with the fragment and a
    set of constant registers.  A fragment program can perform mathematical
    computations and texture lookups using arbitrary texture coordinates.  The
    results of a fragment program are new color and depth values for the
    fragment.

    This extension defines a programming model including a 4-component vector
    instruction set, 16- and 32-bit floating-point data types, and a
    relatively large set of temporary registers.  The programming model also
    includes a condition code vector which can be used to mask register writes
    at run-time or kill fragments altogether.  The syntax, program
    instructions, and general semantics are similar to those in the
    NV_vertex_program and NV_vertex_program2 extensions, which provide for the
    execution of an arbitrary program each time the GL receives a vertex.

    The fragment program execution environment is designed for efficient
    hardware implementation and to support a wide variety of programs.  By
    design, the entire set of existing fragment programs defined by existing
    OpenGL per-fragment computation extensions can be implemented using the
    extension's programming model.

    The fragment program execution environment accesses textures via
    arbitrarily computed texture coordinates.  As such, there is no necessary
    correspondence between the texture coordinates and texture maps previously
    lumped into a single "texture unit".  This extension separates the notion
    of "texture coordinate sets" and "texture image units" (texture maps and
    associated parameters), allowing implementations with a different number
    of each.  The initial implementation of this extension will support 8
    texture coordinate sets and 16 texture image units.

Issues

    What limitations exist in this extension?

        RESOLVED:  Very few.  Programs can not exceed a maximum program length
        (which is no less than 1024 instructions), and can use no more than
        32-64 temporary registers.  Programs can not access more than one
        fragment attribute or program parameter (constant) per instruction,
        but can work around this restriction using temporaries.  The number of
        textures that can be used by a program is limited to the number of
        texture image units provided by the implementation (16 in the initial
        implementation of this extension).

        These limits are fairly high.  Additionally, there is no limit on the
        total number of texture lookups that can be performed by a program.
        There is no limit on the length of a texture dependency chain -- one
        can write a program that performs over 1000 consecutive dependent
        texture lookups.  There is no restrictions on dependencies between
        texture mapping instructions and arithmetic instructions.  Texture
        lookups can be performed using arbitrarily computed texture
        coordinates.  Applications can carry out their calculations with full
        32-bit single precision, although two lower-precision modes are also
        available.

    How does texture mapping work with fragment programs?

        RESOLVED:  This extension provides three instructions used to perform
        texture lookups.

        The "TEX" instruction performs a lookup with the (s,t,r) values taken
        from an interpolated texture coordinate, an arbitrarily computed
        vector, or even a program constant.  The "TXP" instruction performs a
        similar lookup, except that it uses the fourth component of the source
        vector to performs a perspective divide, using (s/q, t/q, r/q).  In
        both cases, the GL will automatically compute partial derivatives used
        for filter and LOD selection.

        The "TXD" instruction operates like "TEX", except that it allows the
        program to explicitly specify two additional vectors containing the
        partial derivatives of the texture coordinate with respect to x and y
        window coordinates.

        All three instructions write a filtered texel value to a temporary or
        output register.  Other than the computation of texture coordinates
        and partial derivatives, texture lookups not performed any differently
        in fragment program mode.  In particular, any applicable LOD biases,
        wrap modes, minification and magnification filters, and anisotropic
        filtering controls are still applied in fragment program mode.

        The results of the texture lookup are available to be used arbitrarily
        by subsequent fragment program instructions.  Fragment programs are
        allowed to access any texture map arbitrarily many times.

    Can fragment programs be used to compute depth values?

         RESOLVED:  Yes.  A fragment program can perform arbitrary
         computations to compute a final value for the fragment, which it
         should write to the "z" component of the o[DEPR] register.  The "z"
         value written should be in the range [0,1], regardless of the size of
         the depth buffer.  

         To assist in the computation of the final Z value, a fragment program
         can access the interpolated depth of the fragment (prior to any
         displacement) by reading the "z" component of the f[WPOS] attribute
         register.

    How should near and far plane clipping work in fragment program mode if
    the current fragment program computes a depth value?

        RESOLVED:  Geometric clipping to the near and far clip plane should be
        disabled.  Clipping should be done based on the depth values computed
        per-fragment.  The rationale is that per-fragment depth displacement
        operations may effectively move portions of a primitive initially
        outside the clip volume inside, and vice versa.

        Note that under the NV_depth_clamp extension, geometric clipping to
        the near and far clip planes is also disabled, and the fragment depth
        values are clamped to the depth range.  If depth clamp mode is enabled
        when using a fragment program that computes a depth value, the
        computed depth value will be clamped to the depth range.

    Should fragment programs be allowed to use multiple precisions for
    operands and operations?

        RESOLVED:  Yes.  Low-precision operands are generally adequate for
        representing colors.  Allowing low-precision registers also allows for
        a larger number of temporary registers (at lower precision).
        Low-precision operations also provide the opportunity for a higher
        level of performance.  

        Applications are free to use only high-precision operations or mix
        high- and low-precision operations as necessary.

    What levels of precision are supported in arithmetic operations?

        RESOLVED:  Arithmetic operations can be performed at three different
        precisions.  32-bit floating point precision (fp32) uses the IEEE
        single-precision standard with a sign bit, 8 exponent bits, and 23
        mantissa bits.  16-bit floating-point precision (fp16) uses a similar
        floating-point representation, but with 5 exponent bits and 10
        mantissa bits.  Additionally, many arithmetic operations can also be
        carried out at 12-bit fixed point precision (fx12), where values in
        the range [-2,+2) are represented as signed values with 10 fraction
        bits.

    How should the precision with which operations are carried out be
    specified?  Should we infer the precision from the types of the operands
    or result vectors?  Or should it be an attribute of the instruction?

        RESOLVED:  Applications can optionally specify the precision of
        individual instructions by adding a suffix of "R", "H", and "X" to
        instruction names to select fp32, fp16, and fx12 precision,
        respectively.  

        By default, instructions will be carried out using the precision of
        the destination register.  Always inferring the precision from the
        operands has a number of issues.  First, there are a number of
        operations (e.g., TEX/TXP/TXD) where result type has little to no
        correspondance to the type of the operands.  In these cases, precision
        suffixes are not supported.  Second, one could have instructions
        automatically cast operands and compute results using the type of the
        highest precision operand or result.  This behavior would be
        problematic since all fragment attribute registers and program
        parameters are kept at full precision, but full precision may not be
        needed by the operation.

        The choice of precision level allows programs to trade off precision
        for potentially higher performance.  Giving the program explicit
        control over the precision also allows it to dictate precision
        explicitly and eliminate any uncertainty over type casting.

    For instructions whose specified precision is different than the precision
    of the operands or the result registers, how are the operations performed?
    How are the condition codes updated?

        RESOLVED:  Operations are performed with operands and results at the
        precision specified by the instruction.  After the operation is
        complete, the result is converted to the precision of the destination
        register, after which the condition code is generated.

        In an alternate approach, the condition code could be generated from
        the result.  However, in some cases, the register contents would not
        match the condition code.  In such cases, it may not be reliable to
        use the condition code to prevent division by zero or other special
        cases.

    How does this extension interact with the ARB_multisample extension?  In
    the ARB_multisample extension, each fragment has multiple depth values.
    In this extension, a single interpolated depth value may be modified by a
    fragment program.

        RESOLVED:  The depth values for the extra samples are generated by
        computing partials of the computed depth value and using these
        partials to derive the depth values for each of the extra samples.

    How does this extension interact with polygon offset?  Both extensions
    modify fragment depth values.

        RESOLVED:  As in the base OpenGL spec, the depth offset generated by
        polygon offset is added during polygon rasterization.  The depth value
        provided to programs in f[WPOS].z already includes polygon offset, if
        enabled.  If the depth value is replaced by a fragment program, the
        polygon offset value will NOT be recomputed and added back after
        program execution.
  
        This is probably not desirable for fragment programs that modify depth
        values since the partials used to generate the offset may not match
        the partials of the computed depth value.  Polygon offset for filled
        polygons can be approximated in a fragment program using the depth
        partials obtained by the DDX and DDY instructions.  This will not work
        properly for line- and point-mode polygons, since the partials used
        for offset are computed over the polygon, while the partials resulting
        from the DDX and DDY instructions are computed along the line (or are
        zero for point-mode polygons).  In addition, separate treatment of
        points, line segments, and polygons is not possible in a fragment
        program.

    Should depth component replacement be an property of the fragment program
    or a separate enable?

        RESOLVED:  It should be a program property.  Using the output register
        notation simplifies matters:  depth components are replaced if and
        only if the DEPR register is written to.  This alleviates the
        application and driver burden of maintaining separate state.

    How does this extension affect the handling of q texture coordinates in
    the OpenGL spec?
       
        RESOLVED:  Fragment programs are allowed to access an associated q
        texture coordinate, so this attribute must be produced by
        rasterization.  In unextended OpenGL 1.2, the q coordinate is
        eliminated in the rasterization portions of the spec after dividing
        each of s, t, and r by it.  This extension updates the specification
        to pass q coordinates through at least to conventional texture
        mapping.  When fragment program mode are disabled, q coordinates will
        be eliminated there in an identical manner.  This modification has the
        added benefit of simplifying the equations used for attribute
        interpolation.

    How should clip w coordinates be handled by this extension?

        RESOLVED:  Fragment programs are allowed to access the reciprocal of
        the clip w coordinate, so this attribute must be produced by
        rasterization.  The OpenGL 1.2 spec doesn't explictly enumerate the
        attributes associated with the fragment, but we add treatment of the w
        clip coordinate in the appropriate locations.  

        The reciprocal of the clip w coordinate in traditional graphics
        hardware is produced by screen-space linear interpolation of the
        reciprocals of the clip w coordinates of the vertices.  However, this
        spec says the clip w coordinate is produced by perspective-correct
        interpolation of the (non-reciprocated) clip w vertex coordinates.
        These two formulations turn out to be equivalent, and the latter is
        more convenient since the core OpenGL spec already contains formulas
        for perspective-correct interpolation of vertex attributes.

    What is produced by the TEX/TXP/TXD instructions if the requested texture
    image is inconsistent?

        RESOLVED:  The result vector is specified to be (0,0,0,0).  This
        behavior is consistent with the NV_texture_shader extension.  Note
        that like in NV_texture_shader, these instructions ignore the standard
        hierarchy of texture enables and programs can access textures that are
        not specifically "enabled".

    Should a minimum precision be specified for certain fragment attribute
    registers (in particular COL0, COL1) that may not be generated with full
    fp32 precision?

        RESOLVED:  No.  It is expected that the precision of COL0/COL1 should
        generally be at least as high as that of the frame buffer.

    Fragment color components (f[COL0] and f[COL1]) are generally
    low-precision fixed-point values in the range [0,1].  Is it possible to
    pass unclamped or high-precision color components to fragment programs?

        RESOLVED:  Yes, although you can't exactly call them "colors".
        High-precision per-vertex color values can be written into any unused
        texture coordinate set, either via a MultiTexCoord call or using a
        vertex program.  These "texture coordinates" will be interpolated
        during rasterization, and can be used arbitrarily by a fragment
        program.

        In particular, there is no requirement that per-fragment attributes
        called "texture coordinates" be used for texture mapping.

    Should this specification guarantee that temporary registers are
    initialized to zero?

        RESOLVED:  Yes.  This will allow for the modular construction of
        programs that accumulate results in registers.  For example,
        per-fragment lighting may use MAD instructions to accumulate color
        contributions at each light.  Without zero-initialization, the program
        would require an explicit MOV instruction to load 0 or the use of the
        MUL instruction for the first light.

    Should this specification support Unicode program strings?

        RESOLVED:  Not necessary.

    Programs defined by NV_vertex_program begin with "!!VP1.0".  Should
    fragment programs have a similar identifier?

        RESOLVED:  Yes, "!!FP1.0", identifying the first revision of this
        fragment program language.

    Should per-fragment attributes have equivalent integer names in the
    program language, as per-vertex attributes do in NV_vertex_program?

        RESOLVED:  No.  In NV_vertex_program, "generic" vertex attributes
        could be specified directly by an application using only an attribute
        number.  Those numbers may have no necessary correlation with the
        conventional attribute names, although conventional vertex attributes
        are mapped to attribute numbers.  However, conventional attributes are
        the only outputs of vertex programs and of rasterization.  Therefore,
        there is no need for a similar input-by-number functionality for
        fragment programs.

    Should we provide the ability to issue instructions that do not update
    temporary or output registers?

        RESOLVED:  Yes.  Programs may issue instructions whose only purpose is
        to update the condition code register, and requiring such instructions
        to write to a temporary may require the use of an additional temporary
        and/or defeat possible program optimizations.  We accomplish this by
        adding two write-only temporary pseudo-registers ("RC" and "HC") that
        can be specified as destination registers.

    Do the packing and unpacking instructions in this extension make any
    sense?

        RESOLVED:  Yes.  They are useful for packing and unpacking multiple
        components in a single channel of a floating-point frame buffer.  For
        example, a 128-bit "RGBA" frame buffer could pack 16 8-bit quantities
        or 8 16-bit quantities, all of which could be used in later
        rasterization passes.  See the NV_float_buffer extension for more
        information.

    Should we provide a method for specifying an fp16 depth component output
    value?

        RESOLVED:  No.  There is no good reason for supporting half-precision
        Z outputs.  Even with 16-bit Z buffers, the 10-bit mantissa of the
        half-precision float is rather limiting.  There would effectively be
        only 11 good bits in the back half of the Z buffer.

    Should RequestResidentProgramsNV (or a new equivalent function) take a
    target?  Dealing with working sets of different program types is a bit
    messy.  Should we document some limitation if we get programs of different
    types?
          
        RESOLVED:  In retrospect, it may have been a good idea to attach a
        target to this command, but there isn't a good reason to mess with
        something that already works for vertex programs.  The driver is
        responsible for ensuring consistent results when the program types
        specified are mixed.
    
    What happens on data type conversions where the original value is not
    exactly representable in the new data type, either due to overflow or
    insufficient precision in the destination type?

        RESOLVED:  In case of overflow, the original value is clamped to the
        +/-INF (fp16 or fp32) or the nearest representable value (fx12).  In
        case of imprecision, the conversion is either to round or truncate to
        the nearest representable value.

    Should this extension support IEEE-style denorms?  For 32-bit IEEE
    floating point, denorms are numbers smaller in absolute value than 2^-126.
    For 16-bit floats used by this extension, denorms are numbers smaller in
    absolute value than 2^-14.

        RESOLVED:  For 32-bit data types, hardware support for denorms was
        considered too expensive relative to the benefit provided.
        Computational results that would otherwise produce denorms are flushed
        to zero.  For 16-bit data types, hardware denorm support will be
        present.  The expense of hardware denorm support is lower and the
        potential precision benefit is greater for 16-bit data types.

    OpenGL provides a hierarchy of texture enables.  The texture lookup
    operations in NV_texture_shader effectively override the texture enable
    hierarchy and select a specific texture to enable.  What should be done by
    this extension?

        RESOLVED:  This extension will build upon NV_texture_shader and reduce
        the driver overhead of validating the texture enables.  Texture
        lookups can be specified by instructions like "TEX H0, f[TEX2], TEX2,
        3D", which would indicate to use texture coordinate set number 2 to do
        a lookup in the texture object bound to the TEXTURE_3D target in
        texture image unit 2.

        Each texture unit can have only one "active" target.  Programs are not
        allowed to reference different texture targets in the same texture
        image unit.  In the example above, any other texture instructions
        using texture image unit 2 must specify the 3D texture target.

    What is the interaction with NV_register_combiners?

        RESOLVED:  Register combiners are not available when fragment programs
        are enabled.

        Previous version of this specification supported the notion of
        combiner programs, where the result of fragment program execution was
        a set of four "texture lookup" values that fed the register combiners.

    For convenience, should we include pseudo-instructions not present in the
    hardware instruction set that are trivially implementable?  For example,
    absolute value and subtract instructions could fall in this category.  An
    "ABS R1,R0" instruction would be equivalent to "MAX R1,R0,-R0", and a "SUB
    R2,R0,R1" would be equivalent to "ADD R2,R0,-R1"

        RESOLVED:  In general, yes.  A SUB instruction is provided for
        convenience.  This extension does not provide a separate ABS
        instruction because it supports absolute value operations of each
        operand.

    Should there be a '+' in the <optionalSign> portion of the grammar?  There
    isn't one in the GL_NV_vertex_program spec.

        RESOLVED:  Yes, for orthogonality/readability.  A '+' obviously adds
        no functionality.  In NV_vertex_program, an <optionalSign> of "-" was
        always a negation operator.  However, in fragment programs, it can
        also be used as a sign for a constant value.

    Can the same fragment attribute register, program parameter register, or
    constants be used for multiple operands in the same instruction?  If so,
    can it be used with different swizzle patterns?

        RESOLVED:  Yes and yes.

    This extension allows different limits for the number of texture
    coordinate sets and the number of texture image units (i.e., texture maps
    and associated data).  The state in ActiveTextureARB affects both
    coordinate sets (TexGen, matrix operations) and image units (TexParameter,
    TexEnv).  How should we deal with this?

        RESOLVED:  Continue to use ActiveTextureARB and emit an
        INVALID_OPERATION if the active texture refers to an unsupported
        coordinate set/image unit.  Other options included creating dummy
        (unusable) state for unsupported coordinate sets/image units and
        continue to use ActiveTextureARB normally, or creating separate state
        and state-setting commands for coordinate sets and image units.
        Separate state is the cleanest solution, but would add more calls and
        potentially cause more programmer confusion.  Dummy state would avoid
        additional error checks, but the demands of dummy state could grow if
        the number of texture image units and texture coordinate sets
        increases.

        The current OpenGL spec is vague as to what state is affected by the
        active texture selector and has no distination between
        coordinate-related and image-related state.  The state tables could
        use a good clean-up in this area.

    The LRP instruction is defined so that the result of "LRP R0, R0, R1, R2"
    is R0*R1+(1-R0)*R2.  There are conflicting precedents here.  The
    definition here matches the "lrp" instruction in the DirectX 8.0 pixel
    shader language.  However, an equivalent RenderMan lerp operation would
    yield a result of (1-R0)*R1+R0*R2.  Which ordering should be implemented?

        RESOLVED:  NVIDIA hardware implements the former operand ordering, and
        there is no good reason to specify a different ordering.  To convert a
        "LRP" using the latter ordering to NV_fragment_program, swap the third
        and fourth arguments.

    Should this extension provide tracking of matrices or any other state,
    similar to that provided in NV_vertex_program?

        RESOLVED:  No.

    Should this extension provide global program parameters -- values shared
    between multiple fragment programs?

        RESOLVED:  No.

    Should this extension provide program parameters specific to a program?
    If so, how?

        RESOLVED:  Yes.  These parameters will be called "local parameters".
        This extension will provide both named and numbered local parameters.
        Local parameters can be managed by the driver and eliminate the need
        for applications to manage a global name space.  

        Named local parameters work much like standard variable names in most
        programming languages.  They are created using the "DECLARE"
        instruction within the fragment program itself.  For example:

            DECLARE color = {1,0,0,1};

        Named local parameters are used simply by referencing the variable
        name.  They do not require the array syntax like the global parameters
        in the NV_vertex_program extension.  They can be updated using the
        commands ProgramNamedParameter4[f,fv]NV.

        Numbered local parameters are not declared.  They are used by simply
        referencing an element of an array called "p".  For example,

            MOV R0, p[12];

        loads the value of numbered local parameter 12 into register R0.
        Numbered local parameters can be updated using the commands
        ProgramLocalParameter4[d,dv,f,fv]ARB.

        The numbered local parameter APIs were added to this extension late in
        its development, and are provided for compatibility with the
        ARB_vertex_program extension, and what will likely be supported in
        ARB_fragment_program as well.  Providing this mechanism allows
        programs to use the same mechanisms to set local parameters in both
        extension.

    Why are the APIs for setting named and numbered local parameters
    different?

        RESOLVED:  The named parameter API was created prior to
        ARB_vertex_program (and the possible future ARB_fragment_program) and
        uses conventions borrowed from NV_vertex_program.  A slightly
        different API was chosen during the ARB standardization process; see
        the ARB_vertex_program specification for more details.

        The named parameter API takes a program ID and a parameter name, and
        sets the parameter for the program with the specified ID.  The
        specified program does not need to be bound (via BindProgramNV) in
        order to modify the values of its named parameters.  The numbered
        parameter API takes a program target enum (FRAGMENT_PROGRAM_NV) and a
        parameter number and modifies the corresponding numbered parameter of
        the currently bound program.

    What should be the initial value of uninitialized local parameters?

        RESOLVED:  (0,0,0,0).  This choice is somewhat arbitrary, but matches
        previous extensions (e.g., NV_vertex_program).

    Should this extension support program parameter arrays?

        RESOLVED:  No hardware support is present.  Note that from the point
        of view of a fragment program, a texture map can be used as a 1-, 2-,
        or 3-dimensional array of constants.
        
    Should this extension provide support constants in fragment programs?  If
    so, how?

        RESOLVED:  Yes.  Scalar or vector constants can be defined inline
        (e.g., "1.0" or "{1,2,3,4}").  In addition, named constants are
        supported using the "DEFINE" instruction, which allow programmers to
        change the values of constants used in multiple instructions simply be
        changing the value assigned to the named constant.

        Note that because this extension uses program strings, the
        floating-point value of any constants generated on the fly must be
        printed to the program string.  An alternate method that avoids the
        need to print constants is to declare a named local program parameter
        and initialize it with the ProgramNamedParameter4[f,fv]() calls.

    Should named constants be allowed to be redefined?

        RESOLVED:  No.  If you want to redefine the values of constants, you
        can create an equivalent named program parameter by changing the
        "DEFINE" keyword to "DECLARE".

    Should functions used to update or query named local parameters take a
    zero-terminated string (as with most strings in the C programming
    language), or should they require an explicit string length?  If the
    former, should we create a version of LoadProgramNV that does not require
    a string length.

        RESOLVED:  Stick with explicit string length.  Strings that are
        defined as constants can have the length computed at compile-time.
        Strings read from files will have the length known in advance.
        Programs to build strings at run-time also likely keep the length
        up-to-date.  Passing an explicit length saves time, since the driver
        doesn't have to do a strlen().

    What is the deal with the alpha of the secondary color?

        RESOLVED:  In unextended OpenGL 1.2, the alpha component of the
        secondary color is forced to 0.0.  In the EXT_secondary_color
        extension, the alpha of the per-vertex secondary colors is defined to
        be 0.0.  NV_vertex_program allows vertex programs to produce a
        per-vertex alpha component, but it is forced to zero for the purposes
        of the color sum.  In the NV_register_combiners extension, the alpha
        component of the secondary color is undefined.  What a mess.

        In this extension, the alpha of the secondary color is well-defined
        and can be used normally.  When in vertex program mode

    Why are fragment program instructions involving f[FOGC] or f[TEX0] through
    f[TEX7] automatically carried out at full precision?

        RESOLVED:  This is an artifact of the method that these interpolants
        are generated the NVIDIA graphics hardware.  If such instructions
        absolutely must be carried out at lower precision, the requirement can
        be met by first loading the interpolants into a temporary register.

    With a different number of texture coordinate sets and texture image
    units, how many copies of each kind of texture state are there?

        RESOLVED:  The intention is that texture state be broken into three
        groups.  (1) There are MAX_TEXTURE_COORDS_NV copies of texture
        coordinate set state, which includes current texture coordinates,
        TexGen state, and texture matrices.  (2) There are
        MAX_TEXTURE_IMAGE_UNITS_NV copies of texture image unit state, which
        include texture maps, texture parameters, LOD bias parameters.  (3)
        There are MAX_TEXTURE_UNITS_ARB copies of legacy OpenGL texture unit
        state (e.g., texture enables, TexEnv blending state), all of which are
        unused when in fragment program mode.

        It is not necessary that MAX_TEXTURE_UNITS_ARB be equal to the minimum
        of MAX_TEXTURE_COORDS_NV and MAX_TEXTURE_IMAGE_UNITS --
        implementations may choose not to extend fixed-function OpenGL texture
        mapping modes beyond a certain point.

    The GLX protocol for LoadProgramNV (and ProgramNamedParameterNV) may end
    up with programs >64KB.  This will overflow the limits of the GLX Render
    protocol, resulting in the need to use RenderLarge path.  This is an issue
    with vertex programs, also.

        RESOLVED:  Yes, it is.

    Should textures used by fragment programs be declared?  For example,
    "TEXTURE TEX3, 2D", indicating that the 2D texture should be used for all
    accesses to texture unit 3.  The dimension could be dropped from the TEX
    family of instructions, and some of the compile-time error checking could
    be dropped.

        RESOLVED:  Maybe it should be, but for better or worse, it isn't.

    It is not all that uncommon to have negative q values with projective
    texture mapping, but results are undefined if any q values are negative in
    this specification.  Why?

        RESOLVED:  This restriction carries on a similar one in the initial
        OpenGL specification.  The motivation for this restriction is that
        when interpolating, it is possible for a fragment to have an
        interpolated q coordinate at or near 0.0.  Since the texture
        coordinates used for projective texture mapping are s/q, t/q, and r/q,
        this will result in a divide-by-zero error or suffer from significant
        numerical instability.  Results will be inaccurate for such fragments.

        Other than the numerical stability issue above, NVIDIA hardware should
        have no problems with negative q coordinates.

    Should programs that replace depth have their own special program type,
    Such as "!!FPD1.0" and "!!FPDC1.0"?

        RESOLVED:  No.  If a program has an instruction that writes to
        o[DEPR], the final fragment depth value is taken from o[DEPR].z.
        Otherwise, the fragment's original depth value is used.

    What fx12 value should NaN map to?

        RESOLVED:  For the lack of any better choice, 0.0.

    How are special-case encodings (-INF, +INF, -0.0, +0.0, NaN) handled for
    arithmetic and comparison operations?

        RESOLVED:  The special cases for all floating-point operations are
        designed to match the IEEE specification for floating-point numbers as
        closely as possible.  The results produced by special cases should be
        enumerated in the sections of this spec describing the operations.
        There are some cases where the implemented fragment program behavior
        does not match IEEE conventions, and these cases should be noted in
        this specification.

    How can condition codes be used to mask out register writes?  How about
    killing fragments?  What other things can you do?

        RESOLVED:  The following example computes a component wise |R1-R2|:

          SUBC R0, R1, R2;      # "C" suffix means update condition code
          MOV  R0 (LT), -R0;    # Conditional write mask in parentheses

        The first instruction computes a component-wise difference between R1
        and R2, storing R1-R2 in register R0.  The "C" suffix in the
        instruction means to update the condition code based on the sign of
        the result vector components.  The second instruction inverts the sign
        of the components of R0.  However the "(LT)" portion says that the
        destination register should be updated only if the corresponding
        condition code component is LT (negative).  This means that only those
        components of R0

        To kill a fragment if the red (x) component of a texture lookup
        returns zero:

          TEXC R0, f[TEX0], TEX0, 2D;
          KIL EQ.x;

        To kill based on the green (y) component, use "EQ.y" instead.  To kill
        if any of the four components is zero, use "EQ.xyzw" or just "EQ".
        
        Fragment programs do not support boolean expressions.  These can
        generally be achieved using conditional write mask.  

        To evaluate the expression "(R0.x == 0) && (R1.x == 0)":

          MOVC RC.x, R0.x;
          MOVC RC.x (EQ), R1.x;

        To evaluate the expression "(R0.x == 0) || (R1.x == 0)":

          MOVC RC.x, R0.x;
          MOVC RC.x (NE), R1.x;

        In both cases, the x component of the condition code will contain "EQ"
        if and only if the condition is TRUE.

    How can fragment programs be used to implement non-standard texture
    filtering modes?

        RESOLVED:  As one example, consider a case where you want to do linear
        filtering in a 2D texture map, but only horizontally.  To achieve
        this, first set the texture filtering mode to NEAREST.  For a 16 x n
        texture, you might do something like:

          DEFINE halfTexel = { 0.03125, 0 };   # 1/32 (1/2 a texel)
          ADD R2, f[TEX0], -halfTexel;         # coords of left sample
          ADD R1, f[TEX0], +halfTexel;         # coords of right sample
          TEX R0, R2, TEX0, 2D;                # lookup left sample
          TEX R1, R1, TEX0, 2D;                # lookup right sample
          MUL R2.x, R2.x, 16;                  # scale X coords to texels
          FRC R2.x, R2.x;                      # get fraction, filter weight
          LRP R0, R2.x, R1, R0;                # blend samples based on weight

        There are plenty of other interesting things that can be done.

    Should this specification provide more examples?

        RESOLVED:  Yes, it should.

    Is the OpenGL ARB working on a multi-vendor standard for fragment
    programmability?  Will there be an ARB_fragment_program extension?  If so,
    how will this extension interact with the ARB standard?

        RESOLVED:  Yes, as of July 2002, there was a multi-vendor working
        group and a draft specification.  The ARB extension is expected to
        have several features not present in this extension, such as state
        tracking and global parameters (called "program environment
        parameters").  It will also likely lack certain features found in this
        extension.

    Why does the HEMI mapping apply to the third component of signed HILO
    textures, but not to unsigned HILO textures?

        RESOLVED:  This behavior matches the behavior of NV_texture_shader
        (e.g., the DOT_PRODUCT_NV mode).  The HEMI mapping will construct the
        third component of a unit vector whose first two components are
        encoded in the HILO texture.


New Procedures and Functions

    void ProgramNamedParameter4fNV(uint id, sizei len, const ubyte *name,
                                   float x, float y, float z, float w);
    void ProgramNamedParameter4dNV(uint id, sizei len, const ubyte *name,
                                   double x, double y, double z, double w);
    void ProgramNamedParameter4fvNV(uint id, sizei len, const ubyte *name,
                                    const float v[]);
    void ProgramNamedParameter4dvNV(uint id, sizei len, const ubyte *name,
                                    const double v[]);
    void GetProgramNamedParameterfvNV(uint id, sizei len, const ubyte *name,
                                      float *params);
    void GetProgramNamedParameterdvNV(uint id, sizei len, const ubyte *name,
                                      double *params);

    void ProgramLocalParameter4dARB(enum target, uint index,
                                    double x, double y, double z, double w);
    void ProgramLocalParameter4dvARB(enum target, uint index,
                                     const double *params);
    void ProgramLocalParameter4fARB(enum target, uint index,
                                    float x, float y, float z, float w);
    void ProgramLocalParameter4fvARB(enum target, uint index,
                                     const float *params);
    void GetProgramLocalParameterdvARB(enum target, uint index,
                                       double *params);
    void GetProgramLocalParameterfvARB(enum target, uint index, 
                                       float *params);


New Tokens


        FRAGMENT_PROGRAM_NV                            0x8870


        MAX_TEXTURE_COORDS_NV                          0x8871
        MAX_TEXTURE_IMAGE_UNITS_NV                     0x8872
        FRAGMENT_PROGRAM_BINDING_NV                    0x8873
        MAX_FRAGMENT_PROGRAM_LOCAL_PARAMETERS_NV       0x8868


        PROGRAM_ERROR_STRING_NV                        0x8874


